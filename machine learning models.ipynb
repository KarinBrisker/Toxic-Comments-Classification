{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# toxic comments classification\n",
    "## by Karin Brisker\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/dahanka1/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import itertools\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (159571, 8)\n",
      "Test shape:  (153164, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv('./Data/train.csv')\n",
    "test_df = pd.read_csv('./Data/test.csv')\n",
    "print('Train shape: ', train_df.shape)\n",
    "print('Test shape: ', test_df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(text, remove_stops=False, stemming=False, lemmatization=False):\n",
    "    text = text.lower().split()\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+\\-=]\", \" \", text)\n",
    "\n",
    "    # Replace apostrophes with standard lexicons\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" \", text)\n",
    "    text = re.sub(r\"\\=\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"isn't\", \"is not\", text)\n",
    "    text = re.sub(r\"aren't\", \"are not\", text)\n",
    "    text = re.sub(r\"ain't\", \"am not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"didn't\", \"did not\", text)\n",
    "    text = re.sub(r\"shan't\", \"shall not\", text)\n",
    "    text = re.sub(r\"haven't\", \"have not\", text)\n",
    "    text = re.sub(r\"hadn't\", \"had not\", text)\n",
    "    text = re.sub(r\"hasn't\", \"has not\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"wasn't\", \"was not\", text)\n",
    "    text = re.sub(r\"weren't\", \"were not\", text)\n",
    "    text = re.sub(r\"doesn't\", \"does not\", text)\n",
    "    text = re.sub(r\"'s\", \" is\", text)\n",
    "    text = re.sub(r\"'re\", \" are\", text)\n",
    "    text = re.sub(r\"'m\", \" am\", text)\n",
    "    text = re.sub(r\"'d\", \" would\", text)\n",
    "    text = re.sub(r\"'ll\", \" will\", text)\n",
    "    text = re.sub(r\"--th\", \" \", text)\n",
    "    text = re.sub('[()\\\"\\t_\\n.,:=!@#$%^&*-/[\\]?|1234567890—]', ' ', text)\n",
    "\n",
    "    # More cleaning\n",
    "    text = re.sub(r\"alot\", \"a lot\", text)\n",
    "    text = re.sub(r\"what's\", \"\", text)\n",
    "    text = re.sub(r\"What's\", \"\", text)\n",
    "\n",
    "    # Remove urls and emails\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', ' ', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Replace words like sooooooo with so\n",
    "    text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(text))\n",
    "\n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "\n",
    "    # Remove all symbols\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+\\-=]\", \" \", text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', r' ', text)\n",
    "    text = re.sub(r'\\n', r' ', text)\n",
    "    text = re.sub('[()\\\"\\t_\\n.,:=!@#$%^&*-/[\\]?|1234567890—]', ' ', text)\n",
    "\n",
    "    text = re.sub(r'\\d +', ' ', text)\n",
    "\n",
    "    if remove_stops:\n",
    "        text = \" \".join([w for w in text.split() if w not in stop_words])\n",
    "\n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "        text = \" \".join([st.stem(w) for w in text.split()])\n",
    "\n",
    "    if lemmatization:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        text = \" \".join([wordnet_lemmatizer.lemmatize(w, pos='v') for w in text.split()])\n",
    "\n",
    "    return text\n",
    "\n",
    "special_character_removal=re.compile(r'[^a-z\\d ]',re.IGNORECASE)\n",
    "replace_numbers=re.compile(r'\\d+',re.IGNORECASE)\n",
    "\n",
    "def text_to_wordlist(text):\n",
    "    text = text.lower().split() \n",
    "    text = \" \".join(text)\n",
    "    text=special_character_removal.sub('',text)\n",
    "    text=replace_numbers.sub('n',text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['comment_text'] = train_df['comment_text'].map(lambda x: cleanData(x))\n",
    "test_df['comment_text'] = test_df['comment_text'].map(lambda x: cleanData(x))\n",
    "\n",
    "list_sentences_train = train_df[\"comment_text\"].fillna(\" \").values\n",
    "list_sentences_test = test_df[\"comment_text\"].fillna(\" \").values\n",
    "\n",
    "train_df[\"comment_text\"] = pd.Series([text_to_wordlist(text) for text in list_sentences_train]).fillna(\" \")\n",
    "test_df[\"comment_text\"] = pd.Series([text_to_wordlist(text) for text in list_sentences_test]).fillna(\" \")\n",
    "\n",
    "all_df = pd.concat([train_df[\"comment_text\"], test_df[\"comment_text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('train.pkl')\n",
    "test_df.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d aww he matches this background colour i am s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i cannot make any real suggestions on imp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  d aww he matches this background colour i am s...      0   \n",
       "2  000113f07ec002fd  hey man i am really not trying to edit war it ...      0   \n",
       "3  0001b41b1c6bb37e  more i cannot make any real suggestions on imp...      0   \n",
       "4  0001d958c54c6e35  you sir are my hero any chance you remember wh...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle('train.pkl')\n",
    "test_df = pd.read_pickle('test.pkl')\n",
    "\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(train_df.columns[2:])\n",
    "\n",
    "y_train = train_df[labels].values\n",
    "y_test = train_df[labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,1), norm='l2')\n",
    "vectorizer.fit(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(train_df['comment_text'])\n",
    "X_test = vectorizer.transform(test_df['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## models\n",
    "\n",
    "define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['MultinomialNB', 'LogisticRegression', 'ExtraTreesClassifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    if name == 'MultinomialNB':\n",
    "        return MultinomialNB()\n",
    "    elif name == 'LogisticRegression':\n",
    "        return LogisticRegression(solver='sag')\n",
    "    elif name == 'ExtraTreesClassifier':\n",
    "        return ExtraTreesClassifier(n_estimators=10)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train & predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save models predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ############# \n",
      "\n",
      "\n",
      " MultinomialNB results: \n",
      "\n",
      "4814\n",
      "Accuracy For toxic Class Is 91.71%\n",
      "285\n",
      "Accuracy For severe_toxic Class Is 99.0%\n",
      "1809\n",
      "Accuracy For obscene Class Is 95.09%\n",
      "147\n",
      "Accuracy For threat Class Is 99.7%\n",
      "1057\n",
      "Accuracy For insult Class Is 95.18%\n",
      "268\n",
      "Accuracy For identity_hate Class Is 99.12%\n",
      "\n",
      " ############# \n",
      "\n",
      "\n",
      " LogisticRegression results: \n",
      "\n",
      "22438\n",
      "Accuracy For toxic Class Is 96.2%\n",
      "933\n",
      "Accuracy For severe_toxic Class Is 99.13%\n",
      "12196\n",
      "Accuracy For obscene Class Is 97.92%\n",
      "162\n",
      "Accuracy For threat Class Is 99.73%\n",
      "8871\n",
      "Accuracy For insult Class Is 97.37%\n",
      "695\n",
      "Accuracy For identity_hate Class Is 99.24%\n",
      "\n",
      " ############# \n",
      "\n",
      "\n",
      " ExtraTreesClassifier results: \n",
      "\n",
      "15052\n",
      "Accuracy For toxic Class Is 99.97%\n",
      "293\n",
      "Accuracy For severe_toxic Class Is 99.98%\n",
      "8715\n",
      "Accuracy For obscene Class Is 99.98%\n",
      "51\n",
      "Accuracy For threat Class Is 99.99%\n",
      "5213\n",
      "Accuracy For insult Class Is 99.96%\n",
      "282\n",
      "Accuracy For identity_hate Class Is 99.99%\n"
     ]
    }
   ],
   "source": [
    "id_df = pd.DataFrame({'id':test_df.id})\n",
    "for model in models:\n",
    "    print('\\n ############# \\n')\n",
    "    print(f'\\n {model} results: \\n')\n",
    "    new = pd.DataFrame(0, index=np.arange(test_df.shape[0]), columns=labels)\n",
    "    for category in labels:\n",
    "        model_x = get_model(model)\n",
    "        model_x.fit(X_train, train_df[category])\n",
    "        pred = list(model_x.predict(X_test))\n",
    "        print(pred.count(1))\n",
    "        new[category] = pred\n",
    "        accuracy = model_x.score(X_train, train_df[category])\n",
    "        print(f\"Accuracy For {category} Class Is {round(accuracy*100,2)}%\")\n",
    "    p_df = pd.DataFrame(new, columns=labels)\n",
    "    p_df_id = pd.concat([id_df, p_df], axis=1)\n",
    "    p_df_id.to_csv(str('ccc') + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = pd.DataFrame({'id':test_df.id})\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "e_pred = pd.DataFrame(0, index=np.arange(test_df.shape[0]), columns=labels)\n",
    "eclf1 = VotingClassifier(estimators=[('MultinomialNB', MultinomialNB()), ('LogisticRegression', LogisticRegression(solver='sag')), ('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators=20))], voting='hard')\n",
    "for category in labels:\n",
    "    eclf1 = eclf1.fit(X_train, train_df[category])\n",
    "    pred = list(eclf1.predict(X_test))\n",
    "    print(pred.count(1))\n",
    "    e_pred[category] = pred\n",
    "    accuracy = eclf1.score(X_train, train_df[category])\n",
    "    print(f\"Accuracy For {category} Class Is {round(accuracy*100,2)}%\")\n",
    "p_df = pd.DataFrame(e_pred, columns=labels)\n",
    "p_df_id = pd.concat([id_df, p_df], axis=1)\n",
    "p_df_id.to_csv('ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
